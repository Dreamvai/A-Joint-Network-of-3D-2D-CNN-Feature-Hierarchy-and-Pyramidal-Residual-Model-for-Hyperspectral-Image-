{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-d139dab2e946>:497: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 TRAIN LOSS 1.912624565037814 TRAIN ACCURACY 37.90909090909091,LOSS 5.0519678592681885 ACCURACY 19.47333354949951\n",
      "EPOCH 1 TRAIN LOSS 1.0678264823826877 TRAIN ACCURACY 67.53030256791548,LOSS 7.943458843231201 ACCURACY 35.96888961791992\n",
      "EPOCH 2 TRAIN LOSS 0.8146112669597972 TRAIN ACCURACY 77.01515128395774,LOSS 5.508854103088379 ACCURACY 46.83888969421387\n",
      "EPOCH 3 TRAIN LOSS 0.4827974723144011 TRAIN ACCURACY 86.60606037486683,LOSS 0.889740812778473 ACCURACY 76.01666793823242\n",
      "EPOCH 4 TRAIN LOSS 0.260459419678558 TRAIN ACCURACY 91.31818181818181,LOSS 0.5449119657278061 ACCURACY 85.73222351074219\n",
      "EPOCH 5 TRAIN LOSS 0.23663134331052954 TRAIN ACCURACY 92.03030256791548,LOSS 0.41919117569923403 ACCURACY 87.58111343383788\n",
      "EPOCH 6 TRAIN LOSS 0.20173352855173024 TRAIN ACCURACY 93.53030256791548,LOSS 0.21609067618846894 ACCURACY 93.18889083862305\n",
      "EPOCH 7 TRAIN LOSS 0.1391046026890928 TRAIN ACCURACY 95.15151492032138,LOSS 0.25538022965192797 ACCURACY 92.56889038085937\n",
      "EPOCH 8 TRAIN LOSS 0.16605536504225296 TRAIN ACCURACY 94.87878764759411,LOSS 0.220865660905838 ACCURACY 93.35222244262695\n",
      "EPOCH 9 TRAIN LOSS 0.19047222557392987 TRAIN ACCURACY 94.57575711337003,LOSS 0.1666707620024681 ACCURACY 94.32889099121094\n",
      "EPOCH 10 TRAIN LOSS 0.14261255006898532 TRAIN ACCURACY 95.71212074973367,LOSS 0.17924917936325074 ACCURACY 94.3933349609375\n",
      "EPOCH 11 TRAIN LOSS 0.10209230130369013 TRAIN ACCURACY 96.04545454545455,LOSS 0.20541393905878066 ACCURACY 93.84000167846679\n",
      "EPOCH 12 TRAIN LOSS 0.09130458398298784 TRAIN ACCURACY 97.43939347700639,LOSS 0.20663819462060928 ACCURACY 93.10555648803711\n",
      "EPOCH 13 TRAIN LOSS 0.05975186570801518 TRAIN ACCURACY 97.89393893155184,LOSS 0.09305718168616295 ACCURACY 97.19333572387696\n",
      "EPOCH 14 TRAIN LOSS 0.0943232552910393 TRAIN ACCURACY 97.78787855668502,LOSS 0.10826988592743873 ACCURACY 97.09889144897461\n",
      "EPOCH 15 TRAIN LOSS 0.086387470533902 TRAIN ACCURACY 96.77272727272727,LOSS 0.266450434923172 ACCURACY 91.66000213623047\n",
      "EPOCH 16 TRAIN LOSS 0.0802832543849945 TRAIN ACCURACY 97.15151492032138,LOSS 0.1240251637995243 ACCURACY 96.12555770874023\n",
      "EPOCH 17 TRAIN LOSS 0.05203118825077333 TRAIN ACCURACY 98.45454545454545,LOSS 0.11390564367175102 ACCURACY 96.96000061035156\n",
      "EPOCH 18 TRAIN LOSS 0.03623583938249133 TRAIN ACCURACY 99.0909090909091,LOSS 0.07431788183748722 ACCURACY 97.51889038085938\n",
      "EPOCH 19 TRAIN LOSS 0.04142315685749054 TRAIN ACCURACY 98.62121165882458,LOSS 0.09080013856291771 ACCURACY 97.31555633544922\n",
      "EPOCH 20 TRAIN LOSS 0.01817710278555751 TRAIN ACCURACY 99.63636363636364,LOSS 0.07445754371583461 ACCURACY 97.85777969360352\n",
      "EPOCH 21 TRAIN LOSS 0.016511559952050447 TRAIN ACCURACY 99.72727272727273,LOSS 0.06620330065488815 ACCURACY 97.98777847290039\n",
      "EPOCH 22 TRAIN LOSS 0.02026804405349222 TRAIN ACCURACY 99.54545454545455,LOSS 0.06885423026978969 ACCURACY 97.86333465576172\n",
      "EPOCH 23 TRAIN LOSS 0.013098078462379899 TRAIN ACCURACY 99.72727272727273,LOSS 0.06486385948956012 ACCURACY 97.72555618286133\n",
      "EPOCH 24 TRAIN LOSS 0.014327487897720526 TRAIN ACCURACY 99.3484843860973,LOSS 0.07199900709092617 ACCURACY 97.67444610595703\n",
      "EPOCH 25 TRAIN LOSS 0.0226734838956459 TRAIN ACCURACY 99.72727272727273,LOSS 0.05935950502753258 ACCURACY 98.10444641113281\n",
      "EPOCH 26 TRAIN LOSS 0.017827499255707317 TRAIN ACCURACY 99.2575752951882,LOSS 0.06739526838064194 ACCURACY 98.14333419799804\n",
      "EPOCH 27 TRAIN LOSS 0.07229157277933237 TRAIN ACCURACY 98.5,LOSS 0.13080926835536957 ACCURACY 96.38000183105468\n",
      "EPOCH 28 TRAIN LOSS 0.08406781096180732 TRAIN ACCURACY 97.69696946577592,LOSS 0.21978106051683427 ACCURACY 93.83555755615234\n",
      "EPOCH 29 TRAIN LOSS 0.08904666208069432 TRAIN ACCURACY 97.98484802246094,LOSS 0.2118244379758835 ACCURACY 93.9433349609375\n",
      "EPOCH 30 TRAIN LOSS 0.04589206996289166 TRAIN ACCURACY 98.54545454545455,LOSS 0.059976626932621 ACCURACY 98.1422248840332\n",
      "EPOCH 31 TRAIN LOSS 0.025716876865110615 TRAIN ACCURACY 99.27272727272727,LOSS 0.09329021386802197 ACCURACY 97.38222427368164\n",
      "EPOCH 32 TRAIN LOSS 0.0753287413072857 TRAIN ACCURACY 98.78787855668502,LOSS 0.062018894031643866 ACCURACY 97.83222351074218\n",
      "EPOCH 33 TRAIN LOSS 0.0741674958685921 TRAIN ACCURACY 97.87878764759411,LOSS 0.11471811160445214 ACCURACY 96.32444686889649\n",
      "EPOCH 34 TRAIN LOSS 0.05321824571795084 TRAIN ACCURACY 97.77272727272727,LOSS 0.11729258298873901 ACCURACY 96.12111358642578\n",
      "EPOCH 35 TRAIN LOSS 0.060813376256688076 TRAIN ACCURACY 98.18181818181819,LOSS 0.05594567023217678 ACCURACY 98.02333526611328\n",
      "EPOCH 36 TRAIN LOSS 0.018589617684483528 TRAIN ACCURACY 99.54545454545455,LOSS 0.05578507743775844 ACCURACY 97.98444519042968\n",
      "EPOCH 37 TRAIN LOSS 0.03514784458093345 TRAIN ACCURACY 99.18181818181819,LOSS 0.10880156680941581 ACCURACY 96.64889144897461\n",
      "EPOCH 38 TRAIN LOSS 0.04607512983916835 TRAIN ACCURACY 98.89393893155184,LOSS 0.10047219917178155 ACCURACY 97.12000122070313\n",
      "EPOCH 39 TRAIN LOSS 0.06065900712697343 TRAIN ACCURACY 98.16666620427912,LOSS 0.0824376542121172 ACCURACY 97.15778045654297\n",
      "EPOCH 40 TRAIN LOSS 0.04506833715872331 TRAIN ACCURACY 98.81818181818181,LOSS 0.09419010058045388 ACCURACY 97.18777999877929\n",
      "EPOCH 41 TRAIN LOSS 0.02298668585717678 TRAIN ACCURACY 99.63636363636364,LOSS 0.06657964438199997 ACCURACY 98.05777969360352\n",
      "EPOCH 42 TRAIN LOSS 0.024398586839776148 TRAIN ACCURACY 99.06060582941228,LOSS 0.05428107045590878 ACCURACY 98.17222366333007\n",
      "EPOCH 43 TRAIN LOSS 0.022916280664503574 TRAIN ACCURACY 99.45454545454545,LOSS 0.05718342382460832 ACCURACY 98.21222305297852\n",
      "EPOCH 44 TRAIN LOSS 0.022475579351356082 TRAIN ACCURACY 98.98484802246094,LOSS 0.08814184404909611 ACCURACY 97.21444473266601\n",
      "EPOCH 45 TRAIN LOSS 0.025464182169261305 TRAIN ACCURACY 99.36363636363636,LOSS 0.08972313180565834 ACCURACY 97.14000091552734\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "from operator import truediv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import argparse\n",
    "import spectral\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "\n",
    "def random_unison(a,b, rstate=None):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.RandomState(seed=rstate).permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "\n",
    "def split_data_fix(pixels, labels, n_samples, rand_state=None):\n",
    "    pixels_number = np.unique(labels, return_counts=1)[1]\n",
    "    train_set_size = [n_samples] * len(np.unique(labels))\n",
    "    tr_size = int(sum(train_set_size))\n",
    "    te_size = int(sum(pixels_number)) - int(sum(train_set_size))\n",
    "    sizetr = np.array([tr_size]+list(pixels.shape)[1:])\n",
    "    sizete = np.array([te_size]+list(pixels.shape)[1:])\n",
    "    train_x = np.empty((sizetr)); train_y = np.empty((tr_size)); test_x = np.empty((sizete)); test_y = np.empty((te_size))\n",
    "    trcont = 0; tecont = 0;\n",
    "    for cl in np.unique(labels):\n",
    "        pixels_cl = pixels[labels==cl]\n",
    "        labels_cl = labels[labels==cl]\n",
    "        pixels_cl, labels_cl = random_unison(pixels_cl, labels_cl, rstate=rand_state)\n",
    "        for cont, (a,b) in enumerate(zip(pixels_cl, labels_cl)):\n",
    "            if cont < train_set_size[cl]:\n",
    "                train_x[trcont,:,:,:] = a\n",
    "                train_y[trcont] = b\n",
    "                trcont += 1\n",
    "            else:\n",
    "                test_x[tecont,:,:,:] = a\n",
    "                test_y[tecont] = b\n",
    "                tecont += 1\n",
    "    train_x, train_y = random_unison(train_x, train_y, rstate=rand_state)\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "def split_data(pixels, labels, percent, splitdset=\"custom\", rand_state=69):\n",
    "    splitdset = \"sklearn\"\n",
    "    if splitdset == \"sklearn\":\n",
    "        return train_test_split(pixels, labels, test_size=(1-percent), stratify=labels, random_state=rand_state)\n",
    "    elif splitdset == \"custom\":\n",
    "        pixels_number = np.unique(labels, return_counts=1)[1]\n",
    "        train_set_size = [int(np.ceil(a*percent)) for a in pixels_number]\n",
    "        tr_size = int(sum(train_set_size))\n",
    "        te_size = int(sum(pixels_number)) - int(sum(train_set_size))\n",
    "        sizetr = np.array([tr_size]+list(pixels.shape)[1:])\n",
    "        sizete = np.array([te_size]+list(pixels.shape)[1:])\n",
    "        train_x = np.empty((sizetr)); train_y = np.empty((tr_size)); test_x = np.empty((sizete)); test_y = np.empty((te_size))\n",
    "        trcont = 0; tecont = 0;\n",
    "        for cl in np.unique(labels):\n",
    "            pixels_cl = pixels[labels==cl]\n",
    "            labels_cl = labels[labels==cl]\n",
    "            pixels_cl, labels_cl = random_unison(pixels_cl, labels_cl, rstate=rand_state)\n",
    "            for cont, (a,b) in enumerate(zip(pixels_cl, labels_cl)):\n",
    "                if cont < train_set_size[cl]:\n",
    "                    train_x[trcont,:,:,:] = a\n",
    "                    train_y[trcont] = b\n",
    "                    trcont += 1\n",
    "                else:\n",
    "                    test_x[tecont,:,:,:] = a\n",
    "                    test_y[tecont] = b\n",
    "                    tecont += 1\n",
    "        train_x, train_y = random_unison(train_x, train_y, rstate=rand_state)\n",
    "        return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "def loadData(name, num_components=None):\n",
    "    data_path = os.path.join(os.getcwd(), 'mnt')\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SV':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
    "    else:\n",
    "        print(\"NO DATASET\")\n",
    "        exit()\n",
    "    \n",
    "    shapeor = data.shape\n",
    "    data = data.reshape(-1, data.shape[-1])\n",
    "    if num_components != None:\n",
    "        data = PCA(n_components=num_components).fit_transform(data)\n",
    "        shapeor = np.array(shapeor)\n",
    "        shapeor[-1] = num_components\n",
    "    #data = MinMaxScaler().fit_transform(data)\n",
    "    data = StandardScaler().fit_transform(data)\n",
    "    data = data.reshape(shapeor)\n",
    "    num_class = len(np.unique(labels)) - 1\n",
    "    return data, labels, num_class\n",
    "\n",
    "\n",
    "\n",
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
    "            #import matplotlib.pyplot as plt\n",
    "            #plt.imshow(patch[:, :, 100])\n",
    "            #plt.show()\n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels.astype(\"int\")\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc\n",
    "\n",
    "\n",
    "def reports(y_pred, y_test, name):\n",
    "    classification = classification_report(y_test, y_pred, digits=6)\n",
    "    oa = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    return classification, confusion, list(np.round(np.array([oa, aa, kappa] + list(each_acc)) * 100, 2))\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    outchannel_ratio = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(x)\n",
    "            featuremap_size = shortcut.size()[2:4]\n",
    "        else:\n",
    "            shortcut = x\n",
    "            featuremap_size = out.size()[2:4]\n",
    "\n",
    "        batch_size = out.size()[0]\n",
    "        residual_channel = out.size()[1]\n",
    "        shortcut_channel = shortcut.size()[1]\n",
    "\n",
    "        if residual_channel != shortcut_channel:\n",
    "            padding = torch.autograd.Variable(\n",
    "                torch.zeros(batch_size, residual_channel - shortcut_channel, featuremap_size[0],\n",
    "                            featuremap_size[1]).cuda())\n",
    "            out += torch.cat((shortcut, padding), 1)\n",
    "        else:\n",
    "            out += shortcut\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    outchannel_ratio = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        if stride == 2:\n",
    "            self.conv2 = nn.Conv2d(planes, planes, kernel_size=8, stride=stride, padding=3, bias=False)\n",
    "        else:\n",
    "            self.conv2 = nn.Conv2d(planes, planes, kernel_size=7, stride=stride, padding=3, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * Bottleneck.outchannel_ratio, kernel_size=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(planes * Bottleneck.outchannel_ratio)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn4(out)\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(x)\n",
    "            featuremap_size = shortcut.size()[2:4]\n",
    "        else:\n",
    "            shortcut = x\n",
    "            featuremap_size = out.size()[2:4]\n",
    "\n",
    "        batch_size = out.size()[0]\n",
    "        residual_channel = out.size()[1]\n",
    "        shortcut_channel = shortcut.size()[1]\n",
    "\n",
    "        if residual_channel != shortcut_channel:\n",
    "            padding = torch.autograd.Variable(\n",
    "                torch.zeros(batch_size, residual_channel - shortcut_channel, featuremap_size[0],\n",
    "                            featuremap_size[1]).cuda())\n",
    "            try:\n",
    "                out += torch.cat((shortcut, padding), 1)\n",
    "            except:\n",
    "                print(\"ERROR\", out.shape, shortcut.shape, padding.shape)\n",
    "                exit()\n",
    "        else:\n",
    "            out += shortcut\n",
    "\n",
    "        return out\n",
    "\n",
    "class mResNet(nn.Module):\n",
    "    def __init__(self, depth, alpha, num_classes, n_bands, avgpoosize, inplanes, bottleneck=False):\n",
    "        super(mResNet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        if bottleneck == True:\n",
    "            n = (depth - 2) // 9\n",
    "            block = Bottleneck\n",
    "        else:\n",
    "            n = (depth - 2) // 6\n",
    "            block = BasicBlock\n",
    "        self.addrate = alpha / (3 * n * 1.0)\n",
    "\n",
    "        self.input_featuremap_dim = self.inplanes\n",
    "        self.conv1 = nn.Conv2d(32, self.input_featuremap_dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
    "\n",
    "        self.featuremap_dim = self.input_featuremap_dim\n",
    "        self.layer1 = self.pyramidal_make_layer(block, n)\n",
    "        self.layer2 = self.pyramidal_make_layer(block, n, stride=2)\n",
    "        self.layer3 = self.pyramidal_make_layer(block, n, stride=2)\n",
    "        self.final_featuremap_dim = self.input_featuremap_dim\n",
    "        self.bn_final = nn.BatchNorm2d(self.final_featuremap_dim)\n",
    "        self.relu_final = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(avgpoosize)\n",
    "        self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def pyramidal_make_layer(self, block, block_depth, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1:  # or self.inplanes != int(round(featuremap_dim_1st)) * block.outchannel_ratio:\n",
    "            downsample = nn.AvgPool2d((2, 2), stride=(2, 2))\n",
    "\n",
    "        layers = []\n",
    "        self.featuremap_dim = self.featuremap_dim + self.addrate\n",
    "        layers.append(block(self.input_featuremap_dim, int(round(self.featuremap_dim)), stride, downsample))\n",
    "        for i in range(1, block_depth):\n",
    "            temp_featuremap_dim = self.featuremap_dim + self.addrate\n",
    "            layers.append(\n",
    "                block(int(round(self.featuremap_dim)) * block.outchannel_ratio, int(round(temp_featuremap_dim)), 1))\n",
    "            self.featuremap_dim = temp_featuremap_dim\n",
    "        self.input_featuremap_dim = int(round(self.featuremap_dim)) * block.outchannel_ratio\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = F.dropout(x)\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.bn_final(x)\n",
    "        x = self.relu_final(x)\n",
    "        #print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class pResNet(nn.Module):\n",
    "    def __init__(self, depth, alpha, num_classes, n_bands, avgpoosize, inplanes, bottleneck=False):\n",
    "        super(pResNet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "\n",
    "        if bottleneck == True:\n",
    "            n = (depth - 2) // 9\n",
    "            block = Bottleneck\n",
    "        else:\n",
    "            n = (depth - 2) // 6\n",
    "            block = BasicBlock\n",
    "        self.addrate = alpha / (3 * n * 1.0)\n",
    "\n",
    "        self.conv3d_1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, kernel_size=(5, 3, 3), stride=1, padding=(0,1,1)),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv3d_2 = nn.Sequential(\n",
    "            nn.Conv3d(8, 16, kernel_size=(3, 3, 3), stride=1, padding=(0,1,1)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.input_featuremap_dim = self.inplanes\n",
    "        self.conv1 = nn.Conv2d((32-6)*16, self.input_featuremap_dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
    "\n",
    "        self.featuremap_dim = self.input_featuremap_dim\n",
    "        self.layer1 = self.pyramidal_make_layer(block, n)\n",
    "        self.layer2 = self.pyramidal_make_layer(block, n, stride=2)\n",
    "        self.layer3 = self.pyramidal_make_layer(block, n, stride=2)\n",
    "        self.final_featuremap_dim = self.input_featuremap_dim\n",
    "        self.bn_final = nn.BatchNorm2d(self.final_featuremap_dim)\n",
    "        #self.bn_final = nn.BatchNorm2d(256)\n",
    "        self.relu_final = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(avgpoosize)\n",
    "\n",
    "        self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def pyramidal_make_layer(self, block, block_depth, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1:  # or self.inplanes != int(round(featuremap_dim_1st)) * block.outchannel_ratio:\n",
    "            downsample = nn.AvgPool2d((2, 2), stride=(2, 2))\n",
    "\n",
    "        layers = []\n",
    "        self.featuremap_dim = self.featuremap_dim + self.addrate\n",
    "        layers.append(block(self.input_featuremap_dim, int(round(self.featuremap_dim)), stride, downsample))\n",
    "        for i in range(1, block_depth):\n",
    "            temp_featuremap_dim = self.featuremap_dim + self.addrate\n",
    "            layers.append(\n",
    "                block(int(round(self.featuremap_dim)) * block.outchannel_ratio, int(round(temp_featuremap_dim)), 1))\n",
    "            self.featuremap_dim = temp_featuremap_dim\n",
    "        self.input_featuremap_dim = int(round(self.featuremap_dim)) * block.outchannel_ratio\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 1,  x.size(1), x.size(2), x.size(3))\n",
    "        x = self.conv3d_1(x)\n",
    "        x = self.conv3d_2(x)\n",
    "        x = self.conv1(x.view(x.size(0), x.size(1)*x.size(2), x.size(3), x.size(4)))\n",
    "        # x = F.dropout(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.bn_final(x)\n",
    "        x = self.relu_final(x)\n",
    "        #print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class HyperData(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset[0].astype(np.float32)\n",
    "        self.labels = []\n",
    "        for n in dataset[1]: self.labels += [int(n)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = torch.from_numpy(np.asarray(self.data[index,:,:,:]))\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __labels__(self):\n",
    "        return self.labels\n",
    "    \n",
    "def load_hyper(args):\n",
    "    data, labels, numclass = loadData(args.dataset, num_components=args.components)\n",
    "    pixels, labels = createImageCubes(data, labels, windowSize=args.spatialsize, removeZeroLabels = True)\n",
    "    bands = pixels.shape[-1]; numberofclass = len(np.unique(labels))\n",
    "    if args.tr_percent < 1: # split by percent\n",
    "        x_train, x_test, y_train, y_test = split_data(pixels, labels, args.tr_percent)\n",
    "    else: # split by samples per class\n",
    "        x_train, x_test, y_train, y_test = split_data_fix(pixels, labels, args.tr_percent)\n",
    "    if args.use_val: x_val, x_test, y_val, y_test = split_data(x_test, y_test, args.val_percent)\n",
    "    del pixels, labels\n",
    "    train_hyper = HyperData((np.transpose(x_train, (0, 3, 1, 2)).astype(\"float32\"),y_train))\n",
    "    test_hyper  = HyperData((np.transpose(x_test, (0, 3, 1, 2)).astype(\"float32\"),y_test))\n",
    "    if args.use_val: val_hyper = HyperData((np.transpose(x_val, (0, 3, 1, 2)).astype(\"float32\"),y_val))\n",
    "    else: val_hyper = None\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "    train_loader = torch.utils.data.DataLoader(train_hyper, batch_size=args.tr_bsize, shuffle=True, **kwargs)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_hyper, batch_size=args.te_bsize, shuffle=False, **kwargs)\n",
    "    val_loader  = torch.utils.data.DataLoader(val_hyper, batch_size=args.te_bsize, shuffle=False, **kwargs)\n",
    "    return train_loader, test_loader, val_loader, numberofclass, bands\n",
    "\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch, use_cuda):\n",
    "    model.train()\n",
    "    accs   = np.ones((len(trainloader))) * -1000.0\n",
    "    losses = np.ones((len(trainloader))) * -1000.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        losses[batch_idx] = loss.item()\n",
    "        accs[batch_idx] = accuracy(outputs.data, targets.data)[0].item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return (np.average(losses), np.average(accs))\n",
    "\n",
    "\n",
    "def test(testloader, model, criterion, epoch, use_cuda):\n",
    "    model.eval()\n",
    "    accs   = np.ones((len(testloader))) * -1000.0\n",
    "    losses = np.ones((len(testloader))) * -1000.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "        outputs = model(inputs)\n",
    "        losses[batch_idx] = criterion(outputs, targets).item()\n",
    "        accs[batch_idx] = accuracy(outputs.data, targets.data, topk=(1,))[0].item()\n",
    "    return (np.average(losses), np.average(accs))\n",
    "\n",
    "\n",
    "def predict(testloader, model, criterion, use_cuda):\n",
    "    model.eval()\n",
    "    predicted = []\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        if use_cuda: inputs = inputs.cuda()\n",
    "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
    "        [predicted.append(a) for a in model(inputs).data.cpu().numpy()]\n",
    "    return np.array(predicted)\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    lr = args.lr * (0.1 ** (epoch // 150)) * (0.1 ** (epoch // 225))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch DCNNs Training')\n",
    "    parser.add_argument('--epochs', default=150, type=int, help='number of total epochs to run')\n",
    "    parser.add_argument('--lr', '--learning-rate', default=0.1, type=float, help='initial learning rate')\n",
    "    parser.add_argument('--components', default=\"32\", type=int, help='dimensionality reduction')\n",
    "    parser.add_argument('--dataset', default='IP', type=str, help='dataset (options: IP, PU, SV, KSC)')\n",
    "    parser.add_argument('--tr_percent', default=0.10, type=float, help='samples of train set')\n",
    "    parser.add_argument('--tr_bsize', default=100, type=int, help='mini-batch train size (default: 100)')\n",
    "    parser.add_argument('--te_bsize', default=1000, type=int, help='mini-batch test size (default: 1000)')\n",
    "    parser.add_argument('--depth', default=32, type=int, help='depth of the network (default: 32)')\n",
    "    parser.add_argument('--alpha', default=48, type=int, help='number of new channel increases per depth (default: 12)')\n",
    "    parser.add_argument('--inplanes', dest='inplanes', default=16, type=int, help='bands before blocks')\n",
    "    parser.add_argument('--no-bottleneck', dest='bottleneck', action='store_false', help='to use basicblock (default: bottleneck)')\n",
    "    parser.add_argument('--spatialsize', dest='spatialsize', default=15, type=int, help='spatial-spectral patch dimension')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
    "    parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float, help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('--use_val', action='store_true', help='Use validation set')\n",
    "    parser.add_argument('--val_percent', default=0.1, type=float, help='samples of val set')\n",
    "    parser.set_defaults(bottleneck=True)\n",
    "    parser.add_argument('-f', type=str, default=\"读取额外的参数\")\n",
    "    best_err1 = 100\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    state = {k: v for k, v in args._get_kwargs()}\n",
    "\n",
    "    train_loader, test_loader, val_loader, num_classes, n_bands = load_hyper(args)\n",
    "\n",
    "    # Use CUDA\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda: torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    if args.spatialsize == 9: avgpoosize = 2   \n",
    "    elif args.spatialsize == 11: avgpoosize = 2\n",
    "    elif args.spatialsize == 13: avgpoosize = 3 \n",
    "    elif args.spatialsize == 15: avgpoosize = 3 \n",
    "    elif args.spatialsize == 17: avgpoosize = 4 \n",
    "    elif args.spatialsize == 19: avgpoosize = 4 \n",
    "    elif args.spatialsize == 7: avgpoosize = 1\n",
    "    elif args.spatialsize == 5: avgpoosize = 1\n",
    "    else: print(\"spatialsize no tested\")\n",
    "\n",
    "\n",
    "    model = pResNet(args.depth, args.alpha, num_classes, n_bands, avgpoosize, args.inplanes, bottleneck=args.bottleneck)\n",
    "    #pResnet is proposed model，mResnet is PResnet\n",
    "    #print(model)\n",
    "    #g = make_dot(model(x), params=dict(model.named_parameters()))\n",
    "    #g.view\n",
    "    #model = wyf.Bottleneck(n_bands, args.inplanes)\n",
    "    if use_cuda: model = model.cuda()\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.Adam(model.parameters())\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay, nesterov=True)\n",
    "\n",
    "    best_acc = -1\n",
    "    for epoch in range(args.epochs):\n",
    "        adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "        train_loss, train_acc = train(train_loader, model, criterion, optimizer, epoch, use_cuda)\n",
    "        if args.use_val: test_loss, test_acc = test(val_loader, model, criterion, epoch, use_cuda)\n",
    "        else: test_loss, test_acc = test(test_loader, model, criterion, epoch, use_cuda)\n",
    "\n",
    "        print(\"EPOCH\", epoch, \"TRAIN LOSS\", train_loss, \"TRAIN ACCURACY\", train_acc, end=',')\n",
    "        print(\"LOSS\", test_loss, \"ACCURACY\", test_acc)\n",
    "        # save model\n",
    "        if test_acc > best_acc:\n",
    "            state = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'acc': test_acc,\n",
    "                    'best_acc': best_acc,\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(state, \"best_model.pth.tar\")\n",
    "            best_acc = test_acc\n",
    "\n",
    "    checkpoint = torch.load(\"best_model.pth.tar\")\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    test_loss, test_acc = test(test_loader, model, criterion, epoch, use_cuda)\n",
    "    print(\"FINAL:      LOSS\", test_loss, \"ACCURACY\", test_acc)\n",
    "    classification, confusion, results = reports(np.argmax(predict(test_loader, model, criterion, use_cuda), axis=1), np.array(test_loader.dataset.__labels__()), args.dataset)\n",
    "    print(classification, args.dataset, results)\n",
    "\n",
    "#     X, y,classo = loadData(args.dataset, num_components=args.components)\n",
    "#     height = y.shape[0]\n",
    "#     width = y.shape[1]\n",
    "#     PATCH_SIZE = args.spatialsize\n",
    "#     outputs = np.zeros((height, width))\n",
    "#     X = padWithZeros(X, PATCH_SIZE // 2)\n",
    "#     # calculate the predicted image\n",
    "#     outputs = np.zeros((height, width))\n",
    "#     for i in range(height):\n",
    "#         for j in range(width):\n",
    "#             if int(y[i, j]) == 0:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 image_patch = X[i:i + PATCH_SIZE, j:j + PATCH_SIZE, :]\n",
    "#                 #print(image_patch.shape)\n",
    "#                 image_patch = image_patch.reshape(1, image_patch.shape[0], image_patch.shape[1], image_patch.shape[2])\n",
    "#                 X_test_image = torch.FloatTensor(image_patch.transpose(0, 3, 1, 2)).cuda()\n",
    "#                 prediction = model(X_test_image)\n",
    "#                 prediction = np.argmax(prediction.detach().cpu().numpy(), axis=1)\n",
    "#                 outputs[i][j] = prediction + 1\n",
    "#         if i % 20 == 0:\n",
    "#             print('... ... row ', i, ' handling ... ...')\n",
    "\n",
    "#     oringal_image = spectral.imshow(classes=y, figsize=(7, 7))\n",
    "#     predict_image = spectral.imshow(classes=outputs.astype(int), figsize=(7, 7))\n",
    "#     spectral.save_rgb(args.dataset + \"10%  3D-2D金字塔残差CNN-原始.jpg\", y.astype(int), colors=spectral.spy_colors)\n",
    "#     spectral.save_rgb(args.dataset + \"10%  3D-2D金字塔残差CNN-预测.jpg\", outputs.astype(int), colors=spectral.spy_colors)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
